<p>
  Over my freshman summer I noticed that some of my projects took more and more computational resources. I had an old, unused but GPU-containing ASUS Zenbook that I might use for training and processing large amount of data, so I could use my laptop for everything else. Initially I would pull my code down from the cloud and manually open and use it to process data, but this became tedious when I wasn't at home and physically near the Zenbook.
</p>
<p>
  I started by adding simple SSH to the Zenbook, something I had used but never on my own machines. I figured out port forwarding on my local router, bought a domain name, set up DDNS, and voila! I had a computer I could access from anywhere. It wasn't long before I realilized that this meant I didn't just have to use it for productive means -- I could perhaps run other, non-programming stuff on it, too.
</p>
<p>
  Over the next few weeks I setup a huge amount of services on the laptop as I realized how easy it was to just download a Docker image and set it up instantly. I automated more things then I ever thought was possible to BE automated. I want a personal cloud? Done. Maybe I should be able to stream media from it? I'll get a Plex server. What if I want to add movies to the server? Sonarr/Radarr. How do I find the movies to download? Jackett. How do I connect them all? Maybe if I get a private subnet... and on and on and on.
</p>
<p>
  Furtermore, I had to make sure that none of these services would interfere with each other, and when (not if) they crashed they would be restarted and wouldn't take down anything else with them. I lost so much data through failures and crashes and downages, but through much effort those downages occured less and less frequently, and when they did I have backups availible. 
</p>
<p>
  Throughout this I learned a lot about server maintinence. How to write bash scripts to move and rename files from A to B, setting up networking, and how to manage backups and increase server reliability.
</p>
